classdeformationtypeaperspectivebcurledconefolddmultifolderandomeasyfrandomhardflatwithperspectivewarpingcurvedwithoutcreasesonesignificantcreaseisvisiblemultiplecreasesonthepagerandomfoldsandsomecrumpleshardcrumplesirregularfoldingtable1classificationofsamplesindoc3dreconstructionqualityforjointtrainingweuseda805eq3weusetheadamsolver15withabatchsizeof40andweightdecayof5x1074thelearningrateisinitiallysetat1x1074andreducedbyafactorof05ifthelossdoesnotreducefor5epochs5experimentsweevaluateourmethodwithmultipleexperimentsonthe130imagebenchmarkfrom23andalsoshowqualitativeresultsonrealimagesfrom45asabaselinewetrainthedocunet23unwarpingmethodonournewdoc3ddatasetfurthermoreweevaluateocrperformanceofourmethodfromadocumentanalysisperspectivefinallyweprovideadetailedablationstudytoshowhowtheuseofthecoordinateconvolutions22andthelosslpaffectunwarpingperformancequalitativeevaluationsareshowninfig75lexpermentallsetupbenchmarkforquantitativeevaluationweclassifythe130imagebenchmark23intosixclassesindicatingsixdifferentlevelsofdeformationcomplexityseetable1thebenchmarkdatasetcontainsvariouskindsofdocumentsincludingimagesgraphicsandmultilingualtextevaluationmetricsweusetwodifferentevaluationschemesbasedonaimagesimilarityandbopticalcharacterrecognitionocrperformanceweusetwoimagesimilaritymetricsmultiscalestructuralsimilaritymsssim42andlocaldistortionld45asquantitativeevaluationcriteriafollowing23ssimcomputesthesimilarityofthemeanpixelvalueandvariancewithineachimagepatchandaveragesoverallthepatchesinanimagemsssimappliesssimatmultiplescalesusingagaussianpyramidbettersuitedfortheevaluationofglobalsimilaritybetweentheresultandgroundtruthldcomputesadensesiftflow20fromtheunwarpeddocumenttothecorrespondingdocumentscanthusfocusingontherectificationoflocaldetailstheparametersofldaresettothedefaultvaluesoftheimplementationprovidedby23forafaircomparisonalltheunwarpedoutputandtargetflatbedscannedimagesareresizedtoa598400pixelareaasrecommendedin23ocraccuracyiscalculatedintermsofcharactererrorratecercerisevaluatedbycalculatingtheeditdistanceed17betweenthereferenceandrecognizedtextedisthetotalnumberofsubstitutionssinsertions7anddeletionsdtoobtainthereferencetextgiventherecognizedtextcereitdnwherenisthenumberofcharactersinthereferencetextwhichisobtainedfromtheflatbedscanneddocumentimages52docunetondoc3dwepresentabaselinevalidationoftheproposeddoc3ddatasetbytrainingthenetworkarchitectureindocunet23onourdatasetdoc3ddocunetisa3dagnosticmodelthearchitectureconsistsoftwostackedunetsdocunettakesa2dimageasinputandoutputsaforwardmappingeachpixelrepresentsthecoordinatesinthetextureimagethesupervisorysignalissolelybasedonthegroundtruthforwardmappingunliketheproposeddewarpnetwhichcandirectlyoutputtheunwarpedimagedocunetneedsseveralpostprocessingstepstoconverttheforwardmappingtothebackwardmappingeachpixelrepresentsthecoordinatesinthewarpedinputimageandthensampletheinputimagetogettheunwarpedresultresultsintable2showsignificantimprovementwhenwetraindocunetondoc3dinsteadofthe2dsyntheticdatasetfrom23thesignificantreductionofld1408to1085signalsabetterlocaldetailrectificationthisimprovementistheresultofboth1thedewarpnetarchitectureand2trainingwithamorephysicallygroundeddoc3ddatasetcomparedtothe2dsyntheticdatasetin2352testdewarpnetantredeclnetbeocmmarkweevaluatebothdewarpnetanddewarpnetrefiedewarpnetaugmentedwiththepostprocessingrefinementnetworkonthedocunetbenchmarkdatasetweprovidecomparisonsonboth1theoverallbenchmarkdatasettable2and2eachclassinthebenchmarkfig6thelatterprovidesdetailedinsightintotheimprovementsofourapproachoverpreviousmethodsfromclassatoeourmodelconsistentlyimprovesmmssimandldoverthepreviousstateoftheartinthemostchallengingclassfwheretheimagesusuallyexhibitmultiplecrumplesandrandomdeformationsourmethodachievescomparableandslightlybetterresultstimeefficiencyofdewarpnetourmodeltakes32msonaveragetoprocessa4kresolutionimagecomparedtodocunet23thisrepresentsa125xspeedupdewarpnetdirectlyoutputstheunwarpedimagewhereasdocunetrequiresanexpensiveseparatepostprocessingstep