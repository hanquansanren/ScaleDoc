dewarpingdocumentimagebydisplacementflowestimation7betweencomputationalcomplexityandrectificationeffecttheencoderextractlocalfeaturebyusingthreeconvolutionallayerswiththreestridesof122and7xkernelsinspiredbythearchitecturetrom214wedesignadilatedresidualblockwhichfuselocalanddilatedsemanticbyutilizinggeneralconvolutiondilatedconvolutionwithrate3andresidualconnectioninthiswaywecanextractdenserandlargerreceptivefielddistortionfeatureafterthatweuseonespatialpyramidwithstackeddilatedconvolutiontoencodeglobalhighlevelsemanticinformationbyparallelandcascadedmannersdistortionfeatureextractorreducesthespatialresolutionandobtaintheglobalfeaturemapsthenwegraduallyrecoverthedisplacementoftheentireimagetherawresolutionfromthespatialfeaturebyusingresicualbleck8withtransposedconvolutionallayerorbilinearlayerweusemultitaskmannertorectifythedocumentimageandseparatetheforegroundandbackgroundtheregressiontaskappliesgroupnormalizationandpreluaftereachconvolutionexceptforthelastlayerandthesegmentationtaskappliesgroupnormalizationandreluaftereachconvolutionexceptforthelastlayerwhichaddsasigmoidlayer33lossfunctionswetrainthedeepneuralnetworkbydefiningfourlossfunctionasaguidetoregressthecompactandsmoothdisplacementandseparatetheforegroundandbackgroundthesegmentationlossweuseinthisworkisthestandardcrossentropylosswhichisdefinedas1xlehd_vilogwi1yslog1pa2iwherenisthenumberofelementsinflowyandrespectivelydenotethegroundtruthandpredictedclassificationweoptimizethenetworkbyminimizingthel1elementwiselosswhichmeasuresthedistanceofpixeldisplacementoftheforegroundbetweenthepredictedflowandthegroundtruthflowweformulatelpfunctionasfollowsny1lpny2aiadadilh3wheremistheelementsofforegroundwhichisspecifiedbygrowndteuthdandddenotethepixeldisplacementingroundtruthandoutputvalueofregressionnetworkrespectivelyalthoughthenetworkcanbetrainedbymeasuringthepixelwiseerrorbetweenthegeneratedflowandthegroundtruthitsdifficulttomakemodelobeythecontinuumassumptionbetweenpixelsasshowninfig5tokeepthevarycontinuouslyfromonepointtoanotherinalocalweproposealocalsmooth