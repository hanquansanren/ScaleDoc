deformationtypeapeespectiveflatwithperspectivewarpingcartodcurvedwithoutcremenovefotdonesignidicantcreaseivinibteg9metfoldmuhiplecreacesonthepagerandomeasyrandomfoldsaadsomecrumples1randomhardhardcrumplesinegularfoldingtie1canlicatonofsampleinoe3dreconuructionquayftjointtrainingwewo305eq3weasetheadamsaver1swithabatchsizeof40andweightdecayof510theratefeiciallysetat107andredacedbyafactorof05iftehessdoesnotreduceforepacta5experimentswecvatuateourmethodwithmultipleexperimeecsonthe1mosamagebenctrmarkfro23andaltostowquabicaiverevates0realimagesfrom45asabaselinewetainshedocunet23uniaepingmethodeecornewdoc3dstacasetfurthermoreweevalvateocrperformanceofcotmethodfromadocamentanalysesperwpectivefinallyweprovideadetailedablationstudytoshowhowtheuseofthecocedieanecomvolutions122andthetonscpaffectunswarpingperformancequateativeevabsationsareshowninfig7s1experimentalsetupbenchmarkvorquantiutiveevaluationweclassifythe12oamagebeachenark28intosixclassesiaadicatiagsixgifferenelevelsofdeformarioncomplexityscetable1thebenchmarkdatasetcoveainsvarioushiedsofdacemensincludingimagesgrapbicsandamaltlingualtextevaluationmetricsweusetwodiffereatevaluationschemesbased0aimagesimilarieyarsbopricalchasacterrecogeitionocrperformancewewietwoimagesimitarirymetricsmultiscalestracsralsimntariymsssim42andlocaldistortionld145aquantitativeevabaationcriteriafollowing23simcomputesthesimilarityofthemeanpixelvaluesadvariancewithineachimagepuschansaveragesoverallthepatchesinammagemsssimagplicnssimatmubighescalesunngagaessianpyramidbettersuitedortheevaleatinofglobalvimilaritybetweenthecesulkandgroundrahldcompaniesadeosesiftfw20ftomnewowarpeddocumenttohecoereyponingdocsinentscanthetfecaningomtherectificationoffocaldetailstheparameteesofldare50110thedefauttvaluesoftheimplementarionprovidedby2forafaircomparisonafltheuewarpedculpaandtargetasbedscannedimagesaveresized108mesonteimorayocrsccoracyiscalculatedintermsofcharactereerorrisechrcerisevaluatedbycalculatingtheediedistanceed17berweenthereferenceindrecognisedtextedisthetotalnumberofsubstitutionsxinsertionsanddcleticondtootmainthereferencetextgiventhereeopnicedtextcer24644nwherenisthemamberofcharacterinthereferencetextwictsésobeainedfrom2docunetondoc3dwepeesentabaselinevalidationoftheproposeddocddatasetbytrainingthenetworkarchiteceareisdounet23onourdamasetdoedocunetisa3dagnosticroodelthearchitectareconsisofowostackedunetsdocunettakes22dimageasinpatandoorpatsaforwardmagpingeachpirelrepeencessthecoordinatesiathetextureimagethesuparviserysignalissalslybasedathegrowndtruthforwardmappingunliketheproposeddewapnetwhichcandirectlycutputtheunwarpedimagedocunetneedsseveralpostprocessingstepstoconverttheforwardmappingtothebackwardmappingeachpéxelrepresentsthecoordinatesimthewarpedimpatmageandthenampletheinputimagesogettheumwarpedresultresultsintable2showsignificanttmprovememwhenweraindectinetondoc3dimnteadofthe2dsyntheticdatasetfrom23thesignificaetreductionofld408w1085signalstesterbocaldetailrectificationthisimprovementistheresultofboth1thedewarpnetarchitectureand2trainingwithamovephysicallygroundeddocmddatasetcomparedtothe20syntheticdatasetin2353testdewarpnetothedoclnetbenchmarkweevalamebocdewarpnetanddewarpnesreflepontprocessingrefinemecsttue2and2cachclansinthebenchmarkfig6theaumterpeowidesdetailedinsightintotheimprovementsofourapproachoverpreviowsmethousfromclansawo6ouremodel