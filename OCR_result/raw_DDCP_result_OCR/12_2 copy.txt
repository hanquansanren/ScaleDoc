deformationtypeperspectiveflatwithperspectivewarpingbcuredcurvedwithoutereasesonefodopesignificantcreaseisvisible4mubtifoldmaltiplecreasesoathepagerandomeasyrandomfoldsandsomecrumples0randomhardhardcrumplesirregularfoldingtable1classisicationofsamplesindocbdreconstructionqualityforjointtrainingweuseda313weusetheadamsolver15withabatchsizethelearningrateisinitiallysetat1107andreducedbyafactorof05ifthelossdoesnotreduceforsepochs5experimentsweevaluateourmethodwithmultipleexperimentsonthe130imagebenchmarkfrom23andalsoshowqualitativeresultsomrealimagesfrom45asabaselinewetrainthedocunet23umwarpingmethodonoarnewdocxddatasetfurthermoreweevaluaicocrperformanceofourmethodfromadocumentanalysisperspectivefinallyweprovideadetailedablationstudytoshowhowtheuseofthecoordinatecoavolutions22andthelosspaffectsnwarpingperformancequalitativeevaluationsareshowninfig751experimentalsetupbenchmarkforquantitativeevaluationweclassifythe130imagebenchmark23intosixclassesindicatingsixdiffercatlevelsofdeformationcomplexityseetable1thebenchmarkdatasetcootainsvariouskindsofdocumentsincludingimagesgraphicsandmultilingualtextevaluationmetricsweusctwodifferentevaluationschemesbasedonaimagesimilarityandbopticalcharacterrecognitionocrperformanceweusetwoimagesimilaritymetricsmultisealestracturalsimilaritymsssim42andlocaldistortionld45asquantitativeevaluationcritcriafollowing23simcomputesthesimilarityofthemeanpixelvalueandvariancewithineachimagepatchandaveragesoverallthepaichesinanimagemsssimappliesssimatmultiplescalesusingagaussianpyramidbettersuitedfortheevalationofglobalsimilaritybetweentheresultandgroundtruthldcomputesadensesiftfow20fromtheunwarpeddocumenttothecorrespondingdocumentscanthusfocusingontherectificatioaoflocaldetailstheparametersofldatesettothedefaultvaloesoftheimplementationprovidedby23farafaircomparisonalltheunwarpedsutputandtargetfathedscannedimagesareresizedtoa598400pixelareaasrecommendedin23ocraccuracyiscalculatedintermsofcharacterexrorratecercerisevaluatedbycalculatingthepitdistanceed17betweenthereferenceundrecognizedtextedisthetotalnumberofsubstitutionsinsertionsanddeletionscdtoobtainthereferencetextgiventhereeognizedtextcer94dnwherenisthenumberofcharactersinthereferencetextwhichisobtainedfrowntheflatbedscanneddocumentimages52docunetondoc3dwepresentabaselinevalidationoftheproposeddoc3ddatasetbytrainingthenctworkarchitectureindowcunet23onourdatasetdoc3ddocunetis3dagnosticmodelthearchitectureconsistsoftwostackedunetsdoctinettakesa2dimageasinputandovtpatsaforwardmappingeachpixelrepresentsthecoordinatesinthetextureimagethesupervisorysigoalissolelybasedonthegrowedtruthforwardmappingunliketheproposeddewarpnetwhichcandirectlyoutputthewnwarpedimagedocunetneedsseveralpostprocessingstepstocomverttheforwardmappingtothebackwardmappingeachpixelrepresentsthecoordinatesinthewarpedinpatimageandthensampletheinputimagetogettheuawarpedresultresultsintable2showsignificantimprovementwhenwetraindocunetoadoc3dinsteadofthe2dsyntheticdatasctfrom23thesignificantredactionofld1408to1085signalsabetterlocaldetailrectificationthisimprovementistheresultofboth1thedewarpnetarchitectureand2trainingwithamorephysicallygroundeddoc3ddatasetcomparedtothe2dsyntheticdatasetin2353testdewarpnetonthedocunetbenchmarkweevaluatebothdewarpnetanddewarpnetrefledewarpnetaugmentedwiththepostprocessingrefinementnctworkonthedocunetbenchmarkdatasctweprovidecomparisonsonboth1theoverallbeschmarkdatasettable2and2eachclassinthebenchmarkfig6thelatterprovidesdetailedinsightimotheimprovementsofourapproachoverpreviousmethodsfromclassatoourmodelconsistentlyimprovesmmssimamdldoverthepreviousstateofiheanathemoatchallecagingclass8wheretheimagesusuallyexhibstmultiplecrumplesandrandomdeformationsourenctbodachievescomparableandslightlybetterresultsonaveragetoprocess44kresohitionimagedocunet23thisrepresentsa125kspeednetdirectlyoatpatstheunwarpedimagerequiresanexpensiveseparatepos